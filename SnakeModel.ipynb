{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have a 20 by 20 matrix, with a body and a head covering 3+ squares. We can represent the head,tail and food in a 20x20x3(channels) array\n",
    "j = open('snakeLogs.json')\n",
    "data = json.load(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateBigArrayOfFramesFromManyGames(array_max, data):\n",
    "    \n",
    "    def create_body_head_food(array_max, instance,data): #instance x 20x20 (two arrays)\n",
    "        plays = len(data[instance]['body'])\n",
    "        image = np.zeros((plays,20,20,3))\n",
    "\n",
    "        for key, value in data[instance]['body'].items():\n",
    "            for idx, point in enumerate(value):\n",
    "                y,x = point[0]-1,point[1]-1 #-1 because the stored array starts at 1, instead of 0\n",
    "                if idx != 0:            #tail\n",
    "                    image[int(key),y,x,0] =1\n",
    "                if idx == 0:            #head\n",
    "                    image[int(key),y,x,1] =1          \n",
    "\n",
    "        for key, value in data[instance]['FoodPos'].items():    #food\n",
    "            y,x = value[0]-1,value[1]-1\n",
    "            image[int(key),y,x,2] =1\n",
    "\n",
    "        return image\n",
    "    \n",
    "    AllGamesImage = np.zeros((array_max,20,20,3))\n",
    "    frames_start=0\n",
    "    for game in data.keys():\n",
    "        tempArray = create_body_head_food(array_max, game,data) \n",
    "        frames_end = frames_start+ (len(tempArray)) #to create start and end for storing the x values\n",
    "        if frames_end > array_max:\n",
    "            return AllGamesImage, frames_start\n",
    "        AllGamesImage[frames_start:frames_end] = tempArray\n",
    "        frames_start = frames_end #set frames start to frames end for next iteration\n",
    "    return AllGamesImage, frames_end\n",
    "\n",
    "def CreateBigArrayofMovesFromManyGames(data):\n",
    "    \n",
    "    def move_made(instance,data):\n",
    "        return np.array(list(data[instance]['FaceDirectionChoice'].values()))        \n",
    "    \n",
    "    AllGamesMoves = np.zeros((1,))\n",
    "    for game in data.keys():\n",
    "        tempArray = move_made(game, data)\n",
    "        AllGamesMoves = np.append(AllGamesMoves, tempArray, axis=0)\n",
    "    return AllGamesMoves[1:]\n",
    "\n",
    "def CreateBigArrayofRewardFromManyGames(data):\n",
    "    \n",
    "    def reward(instance,data):\n",
    "        ListOfReward = (list(data[instance]['CurrentScore'].values()))\n",
    "        RewardArray = np.zeros((len(ListOfReward),))+max(ListOfReward)\n",
    "        return RewardArray\n",
    "\n",
    "    AllGamesReward = np.zeros((1,))\n",
    "    for game in data.keys():\n",
    "        tempArray = reward(game, data)\n",
    "        AllGamesReward = np.append(AllGamesReward, tempArray, axis=0)\n",
    "    return AllGamesReward[1:]\n",
    "\n",
    "def CreateBigArrayOfStartingDirectionFromManyGames(data):\n",
    "    \n",
    "    def DirectionPointing(instance,data): \n",
    "        return np.array(list(data[instance]['StartingDirection'].values()))        \n",
    "    \n",
    "    AllGamesDirectionPointing=np.zeros((1,))\n",
    "    for game in data.keys():\n",
    "        tempArray = DirectionPointing(game,data)\n",
    "        AllGamesDirectionPointing = np.append(AllGamesDirectionPointing,tempArray, axis=0)\n",
    "    return AllGamesDirectionPointing[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken: 0\n",
      "Time Taken: 0\n"
     ]
    }
   ],
   "source": [
    "TimerStart = time.time()\n",
    "image,frames =  CreateBigArrayOfFramesFromManyGames(1000000,data)\n",
    "print(f'Time Taken: {int(time.time()-TimerStart)}')\n",
    "moves =  CreateBigArrayofMovesFromManyGames(data)\n",
    "reward = CreateBigArrayofRewardFromManyGames(data)\n",
    "DirectionPointing = CreateBigArrayOfStartingDirectionFromManyGames(data) \n",
    "image, moves, reward, DirectionPointing =image[:frames], moves[:frames], reward[:frames], DirectionPointing[:frames]\n",
    "print(f'Time Taken: {int(time.time()-TimerStart)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22685, 20, 20, 3), (22685,), (22685,), (22685,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape,moves.shape,reward.shape,DirectionPointing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of Variables\n",
    "----\n",
    "Trainable X (State): Body, Direction Pointining\n",
    "\n",
    "Non-trainable X (Decision): Moves\n",
    "\n",
    "Target Y: reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image, StartingDirection, move, y):\n",
    "#         assert len(X) == len(y), \"Data and labels have to be of equal length!\"\n",
    "        self.image = image.astype('int')\n",
    "        self.StartingDirection = StartingDirection.astype('int')\n",
    "        self.move = StartingDirection.astype('int')\n",
    "        self.y = y.astype('int')\n",
    "\n",
    "    # Not dependent on index+\n",
    "    def __getitem__(self, index):\n",
    "        return self.image[index],self.StartingDirection[index],self.move[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(image, moves, DirectionPointing,reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DatasetsAndDataloaders(dataset, train_perc, val_perc, batch_size):\n",
    "    \n",
    "    def create_TTV_splits(train_perc, val_perc,dataset):\n",
    "        assert train_perc + val_perc < 1, 'val and train percent should add up to <1'\n",
    "        length = len(dataset)\n",
    "        trainSize = int(train_perc * length)\n",
    "        TestValSize = int(length - trainSize)\n",
    "        valSize = int(val_perc * length)\n",
    "        TestSize = int(TestValSize - valSize)\n",
    "\n",
    "        train_dataset, validation_dataset = torch.utils.data.random_split(\n",
    "            dataset, [trainSize, TestValSize])  ## split into 1000 training & 797 validation\n",
    "        validation_dataset, test_dataset  = torch.utils.data.random_split(\n",
    "            validation_dataset, [valSize, TestSize])  ## get test set from validation set\n",
    "\n",
    "        return train_dataset, validation_dataset, test_dataset\n",
    "\n",
    "    def create_dataloaders(train_dataset, validation_dataset, test_dataset, batch_size):\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, )   ### dataloader batches the data\n",
    "        val_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "        return train_dataloader, val_dataloader, test_dataloader\n",
    "    \n",
    "    datasets, dataloaders = {}, {}\n",
    "    train_dataset, validation_dataset, test_dataset = create_TTV_splits(train_perc, val_perc, dataset)\n",
    "    train_dataloader, val_dataloader, test_dataloader = create_dataloaders(train_dataset, validation_dataset, test_dataset, batch_size)\n",
    "    \n",
    "    datasets['train'], datasets['val'], datasets['test'] = train_dataset, validation_dataset, test_dataset\n",
    "    dataloaders['train'], dataloaders['val'], dataloaders['test'] = train_dataloader, val_dataloader, test_dataloader\n",
    "    return datasets, dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, dataloaders = DatasetsAndDataloaders(dataset, 0.7,0.2,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fcdbd035ca0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
